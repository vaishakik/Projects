{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Test_Test.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "S0r0A4mybQmg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Use this to discard all changes and reset "
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "kpj-0jQFXvbz",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#!kill -9 -1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CSMBesutWwVD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!rm -rf /usr/local/cuda/bin"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "173TEeVeUEyl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Uncomment all 'deb-src' lines to allow apt to download source code for dependencies"
      ]
    },
    {
      "metadata": {
        "id": "sEv_0UDCk4Mj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with open('/etc/apt/sources.list') as f:\n",
        "  txt = f.read()\n",
        "with open('/etc/apt/sources.list.backup', 'w') as f:\n",
        "  f.write(txt)\n",
        "with open('/etc/apt/sources.list', 'w') as f:\n",
        "  f.write(txt.replace('# deb-src','deb-src'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RtKPU3y7Uavi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Update apt \n",
        "\n",
        "Install dependencies for Caffe with CUDA\n",
        "\n",
        "Install g++-5: this is a way to make g++, nvcc and boost work together"
      ]
    },
    {
      "metadata": {
        "id": "MgfPbjOEfB3P",
        "colab_type": "code",
        "outputId": "b1c4bce3-44a1-49ac-aa35-8ea1b1b1b333",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1938
        }
      },
      "cell_type": "code",
      "source": [
        "!apt update\n",
        "!apt build-dep caffe-cuda\n",
        "!apt install g++-5"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rIgn:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1710/x86_64  InRelease\n",
            "\u001b[33m\r0% [Connecting to archive.ubuntu.com (91.189.88.152)] [Connecting to archive.ca\u001b[0m\r                                                                               \rIgn:2 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1604/x86_64  InRelease\n",
            "\u001b[33m\r0% [Connecting to archive.ubuntu.com (91.189.88.152)] [Connecting to archive.ca\u001b[0m\r                                                                               \rHit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1710/x86_64  Release\n",
            "\u001b[33m\r0% [Connecting to archive.ubuntu.com (91.189.88.152)] [Connecting to archive.ca\u001b[0m\u001b[33m\r0% [Release.gpg gpgv 564 B] [Waiting for headers] [Waiting for headers] [Waitin\u001b[0m\r                                                                               \rHit:4 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1604/x86_64  Release\n",
            "\u001b[33m\r0% [Release.gpg gpgv 564 B] [Waiting for headers] [Waiting for headers] [Waitin\u001b[0m\r                                                                               \rGet:5 http://security.ubuntu.com/ubuntu bionic-security InRelease [83.2 kB]\n",
            "\u001b[33m\r0% [Release.gpg gpgv 564 B] [Waiting for headers] [Waiting for headers] [5 InRe\u001b[0m\r                                                                               \rGet:6 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease [21.3 kB]\n",
            "\u001b[33m\r0% [Release.gpg gpgv 564 B] [Waiting for headers] [Waiting for headers] [5 InRe\u001b[0m\r                                                                               \rHit:7 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "\u001b[33m\r0% [Release.gpg gpgv 564 B] [Waiting for headers] [5 InRelease 2,586 B/83.2 kB \u001b[0m\r                                                                               \rGet:8 http://archive.canonical.com/ubuntu bionic InRelease [10.2 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Get:13 http://archive.canonical.com/ubuntu bionic/partner Sources [1,906 B]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu bionic/main Sources [1,063 kB]\n",
            "Get:15 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic/main amd64 Packages [27.2 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu bionic-security/main Sources [79.8 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu bionic/multiverse Sources [216 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic/restricted Sources [5,823 B]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu bionic/universe Sources [11.5 MB]\n",
            "Get:20 http://security.ubuntu.com/ubuntu bionic-security/multiverse Sources [1,266 B]\n",
            "Get:21 http://security.ubuntu.com/ubuntu bionic-security/universe Sources [32.5 kB]\n",
            "Get:22 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [300 kB]\n",
            "Get:23 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [135 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu bionic-updates/restricted Sources [2,092 B]\n",
            "Get:25 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse Sources [3,978 B]\n",
            "Get:26 http://archive.ubuntu.com/ubuntu bionic-updates/main Sources [287 kB]\n",
            "Get:27 http://archive.ubuntu.com/ubuntu bionic-updates/universe Sources [168 kB]\n",
            "Get:28 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [900 kB]\n",
            "Get:29 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [618 kB]\n",
            "Get:30 http://archive.ubuntu.com/ubuntu bionic-backports/universe Sources [2,069 B]\n",
            "Fetched 15.6 MB in 3s (4,538 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "12 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "Reading package lists... Done\n",
            "Picking 'caffe-contrib' as source package instead of 'caffe-cuda'\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "Some packages could not be installed. This may mean that you have\n",
            "requested an impossible situation or if you are using the unstable\n",
            "distribution that some required packages have not yet been created\n",
            "or been moved out of Incoming.\n",
            "The following information may help to resolve the situation:\n",
            "\n",
            "The following packages have unmet dependencies:\n",
            " builddeps:caffe-contrib : Depends: nvidia-cuda-toolkit (>= 9.0.176) but it is not going to be installed\n",
            "E: Unable to correct problems, you have held broken packages.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  cpp-5 gcc-5 gcc-5-base libasan2 libgcc-5-dev libisl15 libmpx0\n",
            "  libstdc++-5-dev\n",
            "Suggested packages:\n",
            "  gcc-5-locales g++-5-multilib gcc-5-doc libstdc++6-5-dbg gcc-5-multilib\n",
            "  libgcc1-dbg libgomp1-dbg libitm1-dbg libatomic1-dbg libasan2-dbg\n",
            "  liblsan0-dbg libtsan0-dbg libubsan0-dbg libcilkrts5-dbg libmpx0-dbg\n",
            "  libquadmath0-dbg libstdc++-5-doc\n",
            "The following NEW packages will be installed:\n",
            "  cpp-5 g++-5 gcc-5 gcc-5-base libasan2 libgcc-5-dev libisl15 libmpx0\n",
            "  libstdc++-5-dev\n",
            "0 upgraded, 9 newly installed, 0 to remove and 12 not upgraded.\n",
            "Need to get 29.1 MB of archives.\n",
            "After this operation, 100 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 gcc-5-base amd64 5.5.0-12ubuntu1 [17.1 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libisl15 amd64 0.18-4 [548 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/universe amd64 cpp-5 amd64 5.5.0-12ubuntu1 [7,785 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libasan2 amd64 5.5.0-12ubuntu1 [264 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libmpx0 amd64 5.5.0-12ubuntu1 [9,888 B]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libgcc-5-dev amd64 5.5.0-12ubuntu1 [2,224 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic/universe amd64 gcc-5 amd64 5.5.0-12ubuntu1 [8,357 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libstdc++-5-dev amd64 5.5.0-12ubuntu1 [1,415 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic/universe amd64 g++-5 amd64 5.5.0-12ubuntu1 [8,450 kB]\n",
            "Fetched 29.1 MB in 3s (10.4 MB/s)\n",
            "Selecting previously unselected package gcc-5-base:amd64.\n",
            "(Reading database ... 110842 files and directories currently installed.)\n",
            "Preparing to unpack .../0-gcc-5-base_5.5.0-12ubuntu1_amd64.deb ...\n",
            "Unpacking gcc-5-base:amd64 (5.5.0-12ubuntu1) ...\n",
            "Selecting previously unselected package libisl15:amd64.\n",
            "Preparing to unpack .../1-libisl15_0.18-4_amd64.deb ...\n",
            "Unpacking libisl15:amd64 (0.18-4) ...\n",
            "Selecting previously unselected package cpp-5.\n",
            "Preparing to unpack .../2-cpp-5_5.5.0-12ubuntu1_amd64.deb ...\n",
            "Unpacking cpp-5 (5.5.0-12ubuntu1) ...\n",
            "Selecting previously unselected package libasan2:amd64.\n",
            "Preparing to unpack .../3-libasan2_5.5.0-12ubuntu1_amd64.deb ...\n",
            "Unpacking libasan2:amd64 (5.5.0-12ubuntu1) ...\n",
            "Selecting previously unselected package libmpx0:amd64.\n",
            "Preparing to unpack .../4-libmpx0_5.5.0-12ubuntu1_amd64.deb ...\n",
            "Unpacking libmpx0:amd64 (5.5.0-12ubuntu1) ...\n",
            "Selecting previously unselected package libgcc-5-dev:amd64.\n",
            "Preparing to unpack .../5-libgcc-5-dev_5.5.0-12ubuntu1_amd64.deb ...\n",
            "Unpacking libgcc-5-dev:amd64 (5.5.0-12ubuntu1) ...\n",
            "Selecting previously unselected package gcc-5.\n",
            "Preparing to unpack .../6-gcc-5_5.5.0-12ubuntu1_amd64.deb ...\n",
            "Unpacking gcc-5 (5.5.0-12ubuntu1) ...\n",
            "Selecting previously unselected package libstdc++-5-dev:amd64.\n",
            "Preparing to unpack .../7-libstdc++-5-dev_5.5.0-12ubuntu1_amd64.deb ...\n",
            "Unpacking libstdc++-5-dev:amd64 (5.5.0-12ubuntu1) ...\n",
            "Selecting previously unselected package g++-5.\n",
            "Preparing to unpack .../8-g++-5_5.5.0-12ubuntu1_amd64.deb ...\n",
            "Unpacking g++-5 (5.5.0-12ubuntu1) ...\n",
            "Setting up libisl15:amd64 (0.18-4) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Setting up gcc-5-base:amd64 (5.5.0-12ubuntu1) ...\n",
            "Setting up libmpx0:amd64 (5.5.0-12ubuntu1) ...\n",
            "Setting up libasan2:amd64 (5.5.0-12ubuntu1) ...\n",
            "Setting up libgcc-5-dev:amd64 (5.5.0-12ubuntu1) ...\n",
            "Setting up cpp-5 (5.5.0-12ubuntu1) ...\n",
            "Setting up libstdc++-5-dev:amd64 (5.5.0-12ubuntu1) ...\n",
            "Setting up gcc-5 (5.5.0-12ubuntu1) ...\n",
            "Setting up g++-5 (5.5.0-12ubuntu1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "oWSJURtIU60X",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Download sources for boost\n",
        "\n",
        "Unpack boost"
      ]
    },
    {
      "metadata": {
        "id": "DyImLUmie-w6",
        "colab_type": "code",
        "outputId": "0940be00-ea92-4dff-f4bb-4f483515b36d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        }
      },
      "cell_type": "code",
      "source": [
        "!wget https://dl.bintray.com/boostorg/release/1.67.0/source/boost_1_67_0.tar.bz2\n",
        "!tar --bzip2 -xf boost_1_67_0.tar.bz2"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2018-12-22 05:26:34--  https://dl.bintray.com/boostorg/release/1.67.0/source/boost_1_67_0.tar.bz2\n",
            "Resolving dl.bintray.com (dl.bintray.com)... 52.35.118.217, 52.35.242.184\n",
            "Connecting to dl.bintray.com (dl.bintray.com)|52.35.118.217|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 \n",
            "Location: https://d29vzk4ow07wi7.cloudfront.net/2684c972994ee57fc5632e03bf044746f6eb45d4920c343937a465fd67a5adba?response-content-disposition=attachment%3Bfilename%3D%22boost_1_67_0.tar.bz2%22&Policy=eyJTdGF0ZW1lbnQiOiBbeyJSZXNvdXJjZSI6Imh0dHAqOi8vZDI5dnprNG93MDd3aTcuY2xvdWRmcm9udC5uZXQvMjY4NGM5NzI5OTRlZTU3ZmM1NjMyZTAzYmYwNDQ3NDZmNmViNDVkNDkyMGMzNDM5MzdhNDY1ZmQ2N2E1YWRiYT9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPWF0dGFjaG1lbnQlM0JmaWxlbmFtZSUzRCUyMmJvb3N0XzFfNjdfMC50YXIuYnoyJTIyIiwiQ29uZGl0aW9uIjp7IkRhdGVMZXNzVGhhbiI6eyJBV1M6RXBvY2hUaW1lIjoxNTQ1NDU3MTE0fSwiSXBBZGRyZXNzIjp7IkFXUzpTb3VyY2VJcCI6IjAuMC4wLjAvMCJ9fX1dfQ__&Signature=YtWHvKfwO5n7NyOMDH4UqQjQqL7oJGku78Y2clMHDKX5~EUiXeCI8Vpfn5LsIQ8ZKsrbVt258eG5rDJtaYLHdBdxpbEW42qnPCRomhFpK2UWBOWIcqcLjimRTMU-Ywl6G2c88CGsBcmVhAFMK96FDaIXOJjzY2hupson0qa7ypi5Uw4M3UPp0gyzKPFJWoJH8lLhOAyWgLV3xIkfmOk-0v9W5E8JRvkk3oj1StzcYlTjGucMByEgTYmStkaoG2Rz1CwrfWToEFQYHqSZgLMhsihKtZTqKHW6jqhJFc4n~Pe4rKuERMWP5ozRWeWKR1VkLfJ8VzjG3-dJGMuaniMsoQ__&Key-Pair-Id=APKAIFKFWOMXM2UMTSFA [following]\n",
            "--2018-12-22 05:26:34--  https://d29vzk4ow07wi7.cloudfront.net/2684c972994ee57fc5632e03bf044746f6eb45d4920c343937a465fd67a5adba?response-content-disposition=attachment%3Bfilename%3D%22boost_1_67_0.tar.bz2%22&Policy=eyJTdGF0ZW1lbnQiOiBbeyJSZXNvdXJjZSI6Imh0dHAqOi8vZDI5dnprNG93MDd3aTcuY2xvdWRmcm9udC5uZXQvMjY4NGM5NzI5OTRlZTU3ZmM1NjMyZTAzYmYwNDQ3NDZmNmViNDVkNDkyMGMzNDM5MzdhNDY1ZmQ2N2E1YWRiYT9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPWF0dGFjaG1lbnQlM0JmaWxlbmFtZSUzRCUyMmJvb3N0XzFfNjdfMC50YXIuYnoyJTIyIiwiQ29uZGl0aW9uIjp7IkRhdGVMZXNzVGhhbiI6eyJBV1M6RXBvY2hUaW1lIjoxNTQ1NDU3MTE0fSwiSXBBZGRyZXNzIjp7IkFXUzpTb3VyY2VJcCI6IjAuMC4wLjAvMCJ9fX1dfQ__&Signature=YtWHvKfwO5n7NyOMDH4UqQjQqL7oJGku78Y2clMHDKX5~EUiXeCI8Vpfn5LsIQ8ZKsrbVt258eG5rDJtaYLHdBdxpbEW42qnPCRomhFpK2UWBOWIcqcLjimRTMU-Ywl6G2c88CGsBcmVhAFMK96FDaIXOJjzY2hupson0qa7ypi5Uw4M3UPp0gyzKPFJWoJH8lLhOAyWgLV3xIkfmOk-0v9W5E8JRvkk3oj1StzcYlTjGucMByEgTYmStkaoG2Rz1CwrfWToEFQYHqSZgLMhsihKtZTqKHW6jqhJFc4n~Pe4rKuERMWP5ozRWeWKR1VkLfJ8VzjG3-dJGMuaniMsoQ__&Key-Pair-Id=APKAIFKFWOMXM2UMTSFA\n",
            "Resolving d29vzk4ow07wi7.cloudfront.net (d29vzk4ow07wi7.cloudfront.net)... 52.84.245.13, 52.84.245.142, 52.84.245.17, ...\n",
            "Connecting to d29vzk4ow07wi7.cloudfront.net (d29vzk4ow07wi7.cloudfront.net)|52.84.245.13|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 87336566 (83M) [application/x-bzip2]\n",
            "Saving to: ‘boost_1_67_0.tar.bz2’\n",
            "\n",
            "boost_1_67_0.tar.bz 100%[===================>]  83.29M   128MB/s    in 0.6s    \n",
            "\n",
            "2018-12-22 05:26:35 (128 MB/s) - ‘boost_1_67_0.tar.bz2’ saved [87336566/87336566]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YeCPnAOEVIxF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Set g++-5 and gcc-5 as default compiles: we're gonna use them to compile both boost and Caffe "
      ]
    },
    {
      "metadata": {
        "id": "NBNii3y4e-4i",
        "colab_type": "code",
        "outputId": "e9d11b0a-7730-4af4-bffc-a890cc34a3e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "cell_type": "code",
      "source": [
        "!update-alternatives --remove-all gcc \n",
        "!update-alternatives --remove-all g++\n",
        "\n",
        "!update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-5 20\n",
        "!update-alternatives --install /usr/bin/g++ g++ /usr/bin/g++-5 20\n",
        "\n",
        "!update-alternatives --install /usr/bin/cc cc /usr/bin/gcc 30\n",
        "!update-alternatives --set cc /usr/bin/gcc\n",
        "\n",
        "!update-alternatives --install /usr/bin/c++ c++ /usr/bin/g++ 30\n",
        "!update-alternatives --set c++ /usr/bin/g++"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "update-alternatives: error: no alternatives for gcc\n",
            "update-alternatives: error: no alternatives for g++\n",
            "update-alternatives: using /usr/bin/gcc-5 to provide /usr/bin/gcc (gcc) in auto mode\n",
            "update-alternatives: using /usr/bin/g++-5 to provide /usr/bin/g++ (g++) in auto mode\n",
            "update-alternatives: warning: forcing reinstallation of alternative /usr/bin/gcc because link group cc is broken\n",
            "update-alternatives: warning: forcing reinstallation of alternative /usr/bin/g++ because link group c++ is broken\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "P-42hTqlVYKW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Compile and install boost"
      ]
    },
    {
      "metadata": {
        "id": "YgRViKh3e-7V",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!cd boost_1_67_0 && ./bootstrap.sh --exec-prefix=/usr/local --with-libraries=system,filesystem,regex,thread,python \\\n",
        "--with-python-version=2.7 --with-python-root=/usr\n",
        "!cd boost_1_67_0 && ./b2 install"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "phAvBJueVdfb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Clone Caffe from github, checkout SSD branch"
      ]
    },
    {
      "metadata": {
        "id": "EOEYaahifB92",
        "colab_type": "code",
        "outputId": "79aacefa-8dad-4422-8a31-7f0e5d7286c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/weiliu89/caffe.git && cd caffe "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'caffe'...\n",
            "remote: Enumerating objects: 30179, done.\u001b[K\n",
            "remote: Total 30179 (delta 0), reused 0 (delta 0), pack-reused 30179\u001b[K\n",
            "Receiving objects: 100% (30179/30179), 46.88 MiB | 22.13 MiB/s, done.\n",
            "Resolving deltas: 100% (19578/19578), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ydeP0i77mHxq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with open('caffe/Makefile.config.example') as f:\n",
        "  config = f.read()\n",
        "  \n",
        "comment = ['CUDA_DIR := /usr/local/cuda', \n",
        "           'BLAS := open']\n",
        "uncomment = ['# CUDA_DIR := /usr', \n",
        "             '# BLAS := atlas', \n",
        "             '# OPENCV_VERSION := 3', '# WITH_PYTHON_LAYER := 1'] #\n",
        "replace = [('INCLUDE_DIRS := $(PYTHON_INCLUDE) /usr/local/include',\n",
        "            'INCLUDE_DIRS := $(PYTHON_INCLUDE) /usr/local/include /usr/include/hdf5/serial /usr/local/lib/python2.7/dist-packages/numpy/core/include/'), \n",
        "           ('LIBRARY_DIRS := $(PYTHON_LIB) /usr/local/lib /usr/lib',\n",
        "            'LIBRARY_DIRS := $(PYTHON_LIB) /usr/local/lib /usr/lib /usr/lib/x86_64-linux-gnu/hdf5/serial')]\n",
        "\n",
        "for c in uncomment:\n",
        "  config = config.replace(c, c[2:])\n",
        "for c in comment:\n",
        "  config = config.replace(c, '# '+c)\n",
        "for c1,c2 in replace:\n",
        "  config = config.replace(c1, c2)\n",
        "  \n",
        "with open('caffe/Makefile.config', 'w') as f:\n",
        "  f.write(config)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pX1QrS5FXOjd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Replace '-isystem' in Makefile by '-I' to prevent errors with locating stdlib: adopted from https://github.com/Martchus/tageditor/issues/22"
      ]
    },
    {
      "metadata": {
        "id": "YJIQXflGR4s7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with open('caffe/Makefile') as f:\n",
        "  mfile = f.read()\n",
        "  \n",
        "with open('caffe/Makefile.backup', 'w') as f:\n",
        "  f.write(mfile)\n",
        "  \n",
        "with open('caffe/Makefile', 'w') as f:\n",
        "  f.write(mfile.replace('-isystem','-I'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "k_EfH2KWX-Vq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Magic thing to avoid errors with nan-related types: adopted from \n",
        "\n",
        "https://stackoverflow.com/questions/47200632/caffe-installation-gcc-error-namespace-std-has-no-member-isnan"
      ]
    },
    {
      "metadata": {
        "id": "YZKWknsAmrmA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with open('/usr/include/x86_64-linux-gnu/c++/5/bits/c++config.h') as f:\n",
        "  txt = f.read()\n",
        "with open('/usr/include/x86_64-linux-gnu/c++/5/bits/c++config.h', 'w') as f:\n",
        "  f.write(txt.replace('/* #undef _GLIBCXX_USE_C99_MATH */',\n",
        "                      '/* #undef _GLIBCXX_USE_C99_MATH */\\n#define  _GLIBCXX_USE_C99_MATH  1'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7y9J81O7YkBV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now actually make Caffe, python interface and tests"
      ]
    },
    {
      "metadata": {
        "id": "X2JZnYXJaXyH",
        "colab_type": "code",
        "outputId": "14198a27-8bd5-4e2c-aa45-9d895693243b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "%%writefile caffe/Makefile.config\n",
        "## Refer to http://caffe.berkeleyvision.org/installation.html\n",
        "# Contributions simplifying and improving our build system are welcome!\n",
        "\n",
        "# cuDNN acceleration switch (uncomment to build with cuDNN).\n",
        "# USE_CUDNN := 1\n",
        "\n",
        "# CPU-only switch (uncomment to build without GPU support).\n",
        "#CPU_ONLY := 1\n",
        "\n",
        "# uncomment to disable IO dependencies and corresponding data layers\n",
        "# USE_OPENCV := 0\n",
        "# USE_LEVELDB := 0\n",
        "# USE_LMDB := 0\n",
        "\n",
        "# uncomment to allow MDB_NOLOCK when reading LMDB files (only if necessary)\n",
        "#\tYou should not set this flag if you will be reading LMDBs with any\n",
        "#\tpossibility of simultaneous read and write\n",
        "# ALLOW_LMDB_NOLOCK := 1\n",
        "\n",
        "# Uncomment if you're using OpenCV 3\n",
        "OPENCV_VERSION := 3\n",
        "\n",
        "# To customize your choice of compiler, uncomment and set the following.\n",
        "# N.B. the default for Linux is g++ and the default for OSX is clang++\n",
        " CUSTOM_CXX := g++-5\n",
        "\n",
        "# CUDA directory contains bin/ and lib/ directories that we need.\n",
        "# CUDA_DIR := /usr/local/cuda\n",
        "# On Ubuntu 14.04, if cuda tools are installed via\n",
        "# \"sudo apt-get install nvidia-cuda-toolkit\" then use this instead:\n",
        "CUDA_DIR := /usr\n",
        "\n",
        "# CUDA architecture setting: going with all of them.\n",
        "# For CUDA < 6.0, comment the *_50 through *_61 lines for compatibility.\n",
        "# For CUDA < 8.0, comment the *_60 and *_61 lines for compatibility.\n",
        "CUDA_ARCH := #-gencode arch=compute_20,code=sm_20 \\\n",
        "\t\t#-gencode arch=compute_20,code=sm_21 \\\n",
        "\t\t-gencode arch=compute_30,code=sm_30 \\\n",
        "\t\t-gencode arch=compute_35,code=sm_35 \\\n",
        "\t\t-gencode arch=compute_50,code=sm_50 \\\n",
        "\t\t-gencode arch=compute_52,code=sm_52 \\\n",
        "\t\t-gencode arch=compute_60,code=sm_60 \\\n",
        "\t\t-gencode arch=compute_61,code=sm_61 \\\n",
        "\t\t-gencode arch=compute_61,code=compute_61\n",
        "\n",
        "# BLAS choice:\n",
        "# atlas for ATLAS (default)\n",
        "# mkl for MKL\n",
        "# open for OpenBlas\n",
        "BLAS := atlas\n",
        "# Custom (MKL/ATLAS/OpenBLAS) include and lib directories.\n",
        "# Leave commented to accept the defaults for your choice of BLAS\n",
        "# (which should work)!\n",
        "# BLAS_INCLUDE := /path/to/your/blas\n",
        "# BLAS_LIB := /path/to/your/blas\n",
        "\n",
        "# Homebrew puts openblas in a directory that is not on the standard search path\n",
        "# BLAS_INCLUDE := $(shell brew --prefix openblas)/include\n",
        "# BLAS_LIB := $(shell brew --prefix openblas)/lib\n",
        "\n",
        "# This is required only if you will compile the matlab interface.\n",
        "# MATLAB directory should contain the mex binary in /bin.\n",
        "# MATLAB_DIR := /usr/local\n",
        "# MATLAB_DIR := /Applications/MATLAB_R2012b.app\n",
        "\n",
        "# NOTE: this is required only if you will compile the python interface.\n",
        "# We need to be able to find Python.h and numpy/arrayobject.h.\n",
        "PYTHON_INCLUDE := /usr/include/python2.7 \\\n",
        "\t\t/usr/lib/python2.7/dist-packages/numpy/core/include\n",
        "# Anaconda Python distribution is quite popular. Include path:\n",
        "# Verify anaconda location, sometimes it's in root.\n",
        "# ANACONDA_HOME := $(HOME)/anaconda\n",
        "# PYTHON_INCLUDE := $(ANACONDA_HOME)/include \\\n",
        "\t\t# $(ANACONDA_HOME)/include/python2.7 \\\n",
        "\t\t# $(ANACONDA_HOME)/lib/python2.7/site-packages/numpy/core/include\n",
        "\n",
        "# Uncomment to use Python 3 (default is Python 2)\n",
        "# PYTHON_LIBRARIES := boost_python3 python3.5m\n",
        "# PYTHON_INCLUDE := /usr/include/python3.5m \\\n",
        "#                 /usr/lib/python3.5/dist-packages/numpy/core/include\n",
        "\n",
        "# We need to be able to find libpythonX.X.so or .dylib.\n",
        "PYTHON_LIB := /usr/lib\n",
        "# PYTHON_LIB := $(ANACONDA_HOME)/lib\n",
        "\n",
        "# Homebrew installs numpy in a non standard path (keg only)\n",
        "# PYTHON_INCLUDE += $(dir $(shell python -c 'import numpy.core; print(numpy.core.__file__)'))/include\n",
        "# PYTHON_LIB += $(shell brew --prefix numpy)/lib\n",
        "\n",
        "# Uncomment to support layers written in Python (will link against Python libs)\n",
        "WITH_PYTHON_LAYER := 1\n",
        "\n",
        "# Whatever else you find you need goes here.\n",
        "INCLUDE_DIRS := $(PYTHON_INCLUDE) /usr/local/include /usr/include/hdf5/serial /usr/local/lib/python2.7/dist-packages/numpy/core/include/\n",
        "LIBRARY_DIRS := $(PYTHON_LIB) /usr/local/lib /usr/lib /usr/lib/x86_64-linux-gnu/hdf5/serial\n",
        "\n",
        "# If Homebrew is installed at a non standard location (for example your home directory) and you use it for general dependencies\n",
        "# INCLUDE_DIRS += $(shell brew --prefix)/include\n",
        "# LIBRARY_DIRS += $(shell brew --prefix)/lib\n",
        "\n",
        "# NCCL acceleration switch (uncomment to build with NCCL)\n",
        "# https://github.com/NVIDIA/nccl (last tested version: v1.2.3-1+cuda8.0)\n",
        "# USE_NCCL := 1\n",
        "\n",
        "# Uncomment to use `pkg-config` to specify OpenCV library paths.\n",
        "# (Usually not necessary -- OpenCV libraries are normally installed in one of the above $LIBRARY_DIRS.)\n",
        "#USE_PKG_CONFIG := 1\n",
        "\n",
        "# N.B. both build and distribute dirs are cleared on `make clean`\n",
        "BUILD_DIR := build\n",
        "DISTRIBUTE_DIR := distribute\n",
        "\n",
        "# Uncomment for debugging. Does not work on OSX due to https://github.com/BVLC/caffe/issues/171\n",
        " DEBUG := 1\n",
        "\n",
        "# The ID of the GPU that 'make runtest' will use to run unit tests.\n",
        "TEST_GPUID := 0\n",
        "\n",
        "# enable pretty build (comment to see full commands)\n",
        "Q ?= @\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting caffe/Makefile.config\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qFzUZyXLd_8b",
        "colab_type": "code",
        "outputId": "62bddbca-89f5-466d-a7d8-ae2c68c89bc0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "%%writefile caffe/Makefile.config\n",
        "## Refer to http://caffe.berkeleyvision.org/installation.html\n",
        "# Contributions simplifying and improving our build system are welcome!\n",
        "\n",
        "# cuDNN acceleration switch (uncomment to build with cuDNN).\n",
        "# USE_CUDNN := 1\n",
        "\n",
        "# CPU-only switch (uncomment to build without GPU support).\n",
        "#CPU_ONLY := 1\n",
        "\n",
        "# uncomment to disable IO dependencies and corresponding data layers\n",
        "# USE_OPENCV := 0\n",
        "# USE_LEVELDB := 0\n",
        "# USE_LMDB := 0\n",
        "\n",
        "# uncomment to allow MDB_NOLOCK when reading LMDB files (only if necessary)\n",
        "#\tYou should not set this flag if you will be reading LMDBs with any\n",
        "#\tpossibility of simultaneous read and write\n",
        "# ALLOW_LMDB_NOLOCK := 1\n",
        "\n",
        "# Uncomment if you're using OpenCV 3\n",
        "OPENCV_VERSION := 3\n",
        "\n",
        "# To customize your choice of compiler, uncomment and set the following.\n",
        "# N.B. the default for Linux is g++ and the default for OSX is clang++\n",
        " CUSTOM_CXX := g++-5\n",
        "\n",
        "# CUDA directory contains bin/ and lib/ directories that we need.\n",
        "# CUDA_DIR := /usr/local/cuda\n",
        "# On Ubuntu 14.04, if cuda tools are installed via\n",
        "# \"sudo apt-get install nvidia-cuda-toolkit\" then use this instead:\n",
        "CUDA_DIR := /usr\n",
        "\n",
        "# CUDA architecture setting: going with all of them.\n",
        "# For CUDA < 6.0, comment the *_50 through *_61 lines for compatibility.\n",
        "# For CUDA < 8.0, comment the *_60 and *_61 lines for compatibility.\n",
        "CUDA_ARCH := #-gencode arch=compute_20,code=sm_20 \\\n",
        "\t\t#-gencode arch=compute_20,code=sm_21 \\\n",
        "\t\t-gencode arch=compute_30,code=sm_30 \\\n",
        "\t\t-gencode arch=compute_35,code=sm_35 \\\n",
        "\t\t-gencode arch=compute_50,code=sm_50 \\\n",
        "\t\t-gencode arch=compute_52,code=sm_52 \\\n",
        "\t\t-gencode arch=compute_60,code=sm_60 \\\n",
        "\t\t-gencode arch=compute_61,code=sm_61 \\\n",
        "\t\t-gencode arch=compute_61,code=compute_61\n",
        "\n",
        "# BLAS choice:\n",
        "# atlas for ATLAS (default)\n",
        "# mkl for MKL\n",
        "# open for OpenBlas\n",
        "BLAS := atlas\n",
        "# Custom (MKL/ATLAS/OpenBLAS) include and lib directories.\n",
        "# Leave commented to accept the defaults for your choice of BLAS\n",
        "# (which should work)!\n",
        "# BLAS_INCLUDE := /path/to/your/blas\n",
        "# BLAS_LIB := /path/to/your/blas\n",
        "\n",
        "# Homebrew puts openblas in a directory that is not on the standard search path\n",
        "# BLAS_INCLUDE := $(shell brew --prefix openblas)/include\n",
        "# BLAS_LIB := $(shell brew --prefix openblas)/lib\n",
        "\n",
        "# This is required only if you will compile the matlab interface.\n",
        "# MATLAB directory should contain the mex binary in /bin.\n",
        "# MATLAB_DIR := /usr/local\n",
        "# MATLAB_DIR := /Applications/MATLAB_R2012b.app\n",
        "\n",
        "# NOTE: this is required only if you will compile the python interface.\n",
        "# We need to be able to find Python.h and numpy/arrayobject.h.\n",
        "PYTHON_INCLUDE := /usr/include/python2.7 \\\n",
        "\t\t/usr/lib/python2.7/dist-packages/numpy/core/include\n",
        "# Anaconda Python distribution is quite popular. Include path:\n",
        "# Verify anaconda location, sometimes it's in root.\n",
        "# ANACONDA_HOME := $(HOME)/anaconda\n",
        "# PYTHON_INCLUDE := $(ANACONDA_HOME)/include \\\n",
        "\t\t# $(ANACONDA_HOME)/include/python2.7 \\\n",
        "\t\t# $(ANACONDA_HOME)/lib/python2.7/site-packages/numpy/core/include\n",
        "\n",
        "# Uncomment to use Python 3 (default is Python 2)\n",
        "# PYTHON_LIBRARIES := boost_python3 python3.5m\n",
        "# PYTHON_INCLUDE := /usr/include/python3.5m \\\n",
        "#                 /usr/lib/python3.5/dist-packages/numpy/core/include\n",
        "\n",
        "# We need to be able to find libpythonX.X.so or .dylib.\n",
        "PYTHON_LIB := /usr/lib\n",
        "# PYTHON_LIB := $(ANACONDA_HOME)/lib\n",
        "\n",
        "# Homebrew installs numpy in a non standard path (keg only)\n",
        "# PYTHON_INCLUDE += $(dir $(shell python -c 'import numpy.core; print(numpy.core.__file__)'))/include\n",
        "# PYTHON_LIB += $(shell brew --prefix numpy)/lib\n",
        "\n",
        "# Uncomment to support layers written in Python (will link against Python libs)\n",
        "WITH_PYTHON_LAYER := 1\n",
        "\n",
        "# Whatever else you find you need goes here.\n",
        "INCLUDE_DIRS := $(PYTHON_INCLUDE) /usr/local/include /usr/include/hdf5/serial /usr/local/lib/python2.7/dist-packages/numpy/core/include/\n",
        "LIBRARY_DIRS := $(PYTHON_LIB) /usr/local/lib /usr/lib /usr/lib/x86_64-linux-gnu/hdf5/serial\n",
        "\n",
        "# If Homebrew is installed at a non standard location (for example your home directory) and you use it for general dependencies\n",
        "# INCLUDE_DIRS += $(shell brew --prefix)/include\n",
        "# LIBRARY_DIRS += $(shell brew --prefix)/lib\n",
        "\n",
        "# NCCL acceleration switch (uncomment to build with NCCL)\n",
        "# https://github.com/NVIDIA/nccl (last tested version: v1.2.3-1+cuda8.0)\n",
        "# USE_NCCL := 1\n",
        "\n",
        "# Uncomment to use `pkg-config` to specify OpenCV library paths.\n",
        "# (Usually not necessary -- OpenCV libraries are normally installed in one of the above $LIBRARY_DIRS.)\n",
        "#USE_PKG_CONFIG := 1\n",
        "\n",
        "# N.B. both build and distribute dirs are cleared on `make clean`\n",
        "BUILD_DIR := build\n",
        "DISTRIBUTE_DIR := distribute\n",
        "\n",
        "# Uncomment for debugging. Does not work on OSX due to https://github.com/BVLC/caffe/issues/171\n",
        " DEBUG := 1\n",
        "\n",
        "# The ID of the GPU that 'make runtest' will use to run unit tests.\n",
        "TEST_GPUID := 0\n",
        "\n",
        "# enable pretty build (comment to see full commands)\n",
        "Q ?= @\n",
        "                                                                               "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting caffe/Makefile.config\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qozE08w4fCJY",
        "colab_type": "code",
        "outputId": "f81100d9-193c-40ff-bac2-38d747a2317c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1139
        }
      },
      "cell_type": "code",
      "source": [
        "!cd caffe && make clean && make -j8 && make pycaffe && make test -j8 && make distribute"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PROTOC src/caffe/proto/caffe.proto\n",
            "CXX src/caffe/layers/bnll_layer.cpp\n",
            "CXX src/caffe/layers/log_layer.cpp\n",
            "CXX src/caffe/solver.cpp\n",
            "CXX src/caffe/layer_factory.cpp\n",
            "CXX src/caffe/layers/hdf5_output_layer.cpp\n",
            "CXX src/caffe/layers/flatten_layer.cpp\n",
            "CXX src/caffe/layers/loss_layer.cpp\n",
            "CXX src/caffe/layers/lstm_layer.cpp\n",
            "In file included from ./include/caffe/blob.hpp:8:0,\n",
            "                 from ./include/caffe/layers/flatten_layer.hpp:6,\n",
            "                 from src/caffe/layers/flatten_layer.cpp:3:\n",
            "./include/caffe/common.hpp:5:27: fatal error: gflags/gflags.h: No such file or directory\n",
            "compilation terminated.\n",
            "Makefile:581: recipe for target '.build_debug/src/caffe/layers/flatten_layer.o' failed\n",
            "make: *** [.build_debug/src/caffe/layers/flatten_layer.o] Error 1\n",
            "make: *** Waiting for unfinished jobs....\n",
            "In file included from ./include/caffe/blob.hpp:8:0,\n",
            "                 from ./include/caffe/layers/bnll_layer.hpp:6,\n",
            "                 from src/caffe/layers/bnll_layer.cpp:4:\n",
            "./include/caffe/common.hpp:5:27: fatal error: gflags/gflags.h: No such file or directory\n",
            "compilation terminated.\n",
            "Makefile:581: recipe for target '.build_debug/src/caffe/layers/bnll_layer.o' failed\n",
            "make: *** [.build_debug/src/caffe/layers/bnll_layer.o] Error 1\n",
            "In file included from ./include/caffe/blob.hpp:8:0,\n",
            "                 from ./include/caffe/layers/log_layer.hpp:6,\n",
            "                 from src/caffe/layers/log_layer.cpp:3:\n",
            "./include/caffe/common.hpp:5:27: fatal error: gflags/gflags.h: No such file or directory\n",
            "compilation terminated.\n",
            "Makefile:581: recipe for target '.build_debug/src/caffe/layers/log_layer.o' failed\n",
            "make: *** [.build_debug/src/caffe/layers/log_layer.o] Error 1\n",
            "In file included from ./include/caffe/blob.hpp:8:0,\n",
            "                 from ./include/caffe/layers/loss_layer.hpp:6,\n",
            "                 from src/caffe/layers/loss_layer.cpp:3:\n",
            "./include/caffe/common.hpp:5:27: fatal error: gflags/gflags.h: No such file or directory\n",
            "compilation terminated.\n",
            "Makefile:581: recipe for target '.build_debug/src/caffe/layers/loss_layer.o' failed\n",
            "make: *** [.build_debug/src/caffe/layers/loss_layer.o] Error 1\n",
            "In file included from ./include/caffe/blob.hpp:8:0,\n",
            "                 from ./include/caffe/layers/hdf5_output_layer.hpp:9,\n",
            "                 from src/caffe/layers/hdf5_output_layer.cpp:6:\n",
            "./include/caffe/common.hpp:5:27: fatal error: gflags/gflags.h: No such file or directory\n",
            "compilation terminated.\n",
            "Makefile:581: recipe for target '.build_debug/src/caffe/layers/hdf5_output_layer.o' failed\n",
            "make: *** [.build_debug/src/caffe/layers/hdf5_output_layer.o] Error 1\n",
            "In file included from ./include/caffe/blob.hpp:8:0,\n",
            "                 from src/caffe/layers/lstm_layer.cpp:4:\n",
            "./include/caffe/common.hpp:5:27: fatal error: gflags/gflags.h: No such file or directory\n",
            "compilation terminated.\n",
            "Makefile:581: recipe for target '.build_debug/src/caffe/layers/lstm_layer.o' failed\n",
            "make: *** [.build_debug/src/caffe/layers/lstm_layer.o] Error 1\n",
            "In file included from ./include/caffe/blob.hpp:8:0,\n",
            "                 from ./include/caffe/net.hpp:10,\n",
            "                 from ./include/caffe/solver.hpp:7,\n",
            "                 from src/caffe/solver.cpp:6:\n",
            "./include/caffe/common.hpp:5:27: fatal error: gflags/gflags.h: No such file or directory\n",
            "compilation terminated.\n",
            "Makefile:581: recipe for target '.build_debug/src/caffe/solver.o' failed\n",
            "make: *** [.build_debug/src/caffe/solver.o] Error 1\n",
            "In file included from ./include/caffe/blob.hpp:8:0,\n",
            "                 from ./include/caffe/layer.hpp:8,\n",
            "                 from src/caffe/layer_factory.cpp:8:\n",
            "./include/caffe/common.hpp:5:27: fatal error: gflags/gflags.h: No such file or directory\n",
            "compilation terminated.\n",
            "Makefile:581: recipe for target '.build_debug/src/caffe/layer_factory.o' failed\n",
            "make: *** [.build_debug/src/caffe/layer_factory.o] Error 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "htyw1kATYsBL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Add path with installed libs (namely boost and caffe) to configs"
      ]
    },
    {
      "metadata": {
        "id": "_gzO5QP0-5RY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!echo /usr/local/lib >> /etc/ld.so.conf && ldconfig\n",
        "!echo /content/caffe/distribute/lib >> /etc/ld.so.conf && ldconfig"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fq3tYzSrY15e",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We are ready to test Caffe!"
      ]
    },
    {
      "metadata": {
        "id": "PAcSTF7ufBvp",
        "colab_type": "code",
        "outputId": "4de1f242-4502-43a2-b1d2-c2bb46f217f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 625
        }
      },
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import os\n",
        "caffe_path = !cd /content/caffe/python && pwd\n",
        "sys.path.insert(0, caffe_path[0])  \n",
        "import caffe\n",
        "\n",
        "import cv2\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m\u001b[0m",
            "\u001b[0;31mImportError\u001b[0mTraceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-a3a2c66a8708>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcaffe_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetoutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mu'cd /content/caffe/python && pwd'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaffe_path\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcaffe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/caffe/python/caffe/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpycaffe\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSGDSolver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNesterovSolver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAdaGradSolver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRMSPropSolver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAdaDeltaSolver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAdamSolver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNCCL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTimer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_caffe\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minit_log\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_mode_cpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_mode_gpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_device\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_solver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_type_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_random_seed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_solver_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_rank\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_solver_rank\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_multiprocess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_nccl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_caffe\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__version__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaffe_pb2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTEST\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/caffe/python/caffe/pycaffe.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_caffe\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSGDSolver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNesterovSolver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAdaGradSolver\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mRMSPropSolver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAdaDeltaSolver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAdamSolver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNCCL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTimer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcaffe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: No module named _caffe",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "zwB-rR75hjLf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8QvvpKYRXuot",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/s9xie/hed.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4spRfabWX9aW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "os.chdir('/content/hed/')\n",
        "os.mkdir('data')\n",
        "os.chdir('data')\n",
        "!wget http://vcl.ucsd.edu/hed/HED-BSDS.tar\n",
        "!tar -xvf HED-BSDS.tar\n",
        "!rm HED-BSDS.tar"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8x7W8H0cjAJc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "os.chdir(\"/content/hed/examples/hed\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oBm44nY4YVt2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!wget http://vcl.ucsd.edu/hed/5stage-vgg.caffemodel"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lpDKRYzxYde_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!wget http://vcl.ucsd.edu/hed/hed_pretrained_bsds.caffemodel"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-wLJU-GMYjVu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.pylab as pylab\n",
        "import matplotlib.cm as cm\n",
        "%matplotlib inline\n",
        "import scipy.misc\n",
        "from PIL import Image\n",
        "import scipy.io\n",
        "import os\n",
        "\n",
        "\n",
        "caffe_path = !cd /content/caffe/python && pwd\n",
        "sys.path.insert(0, caffe_path[0])  \n",
        "import caffe"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vkoeV6VZYmmG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data_root = '/content/hed/data/HED-BSDS/'\n",
        "with open(data_root+'test.lst') as f:\n",
        "    test_lst = f.readlines()\n",
        "    \n",
        "test_lst = [data_root+x.strip() for x in test_lst]\n",
        "\n",
        "\n",
        "im_lst = []\n",
        "for i in range(0, len(test_lst)):\n",
        "    im = Image.open(test_lst[i])\n",
        "    in_ = np.array(im, dtype=np.float32)\n",
        "    in_ = in_[:,:,::-1]\n",
        "    in_ -= np.array((104.00698793,116.66876762,122.67891434))\n",
        "    im_lst.append(in_)\n",
        "def plot_single_scale(scale_lst, size):\n",
        "    pylab.rcParams['figure.figsize'] = size, size/2\n",
        "    \n",
        "    plt.figure()\n",
        "    for i in range(0, len(scale_lst)):\n",
        "        s=plt.subplot(1,5,i+1)\n",
        "        plt.imshow(1-scale_lst[i], cmap = cm.Greys_r)\n",
        "        s.set_xticklabels([])\n",
        "        s.set_yticklabels([])\n",
        "        s.yaxis.set_ticks_position('none')\n",
        "        s.xaxis.set_ticks_position('none')\n",
        "    plt.tight_layout()\n",
        "idx = 1\n",
        "\n",
        "in_ = im_lst[idx]\n",
        "in_ = in_.transpose((2,0,1))\n",
        "#remove the following two lines if testing with cpu\n",
        "caffe.set_mode_gpu()\n",
        "caffe.set_device(0)\n",
        "# load net\n",
        "model_root = './'\n",
        "net = caffe.Net(model_root+'deploy.prototxt', model_root+'hed_pretrained_bsds.caffemodel', caffe.TEST)\n",
        "# shape for input (data blob is N x C x H x W), set data\n",
        "net.blobs['data'].reshape(1, *in_.shape)\n",
        "net.blobs['data'].data[...] = in_\n",
        "# run net and take argmax for prediction\n",
        "net.forward()\n",
        "out1 = net.blobs['sigmoid-dsn1'].data[0][0,:,:]\n",
        "out2 = net.blobs['sigmoid-dsn2'].data[0][0,:,:]\n",
        "out3 = net.blobs['sigmoid-dsn3'].data[0][0,:,:]\n",
        "out4 = net.blobs['sigmoid-dsn4'].data[0][0,:,:]\n",
        "out5 = net.blobs['sigmoid-dsn5'].data[0][0,:,:]\n",
        "fuse = net.blobs['sigmoid-fuse'].data[0][0,:,:]\n",
        "\n",
        "scale_lst = [fuse]\n",
        "plot_single_scale(scale_lst, 22)\n",
        "scale_lst = [out1, out2, out3, out4, out5]\n",
        "plot_single_scale(scale_lst, 10)    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YhlYP0fOjs1g",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "os.chdir('/content')\n",
        "!git clone https://github.com/stupidZZ/FCN_Text.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "W4S_BwVMj55h",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "os.chdir('/content')\n",
        "!wget http://www.iapr-tc11.org/dataset/MSRA-TD500/MSRA-TD500.zip\n",
        "!mkdir data\n",
        "!unzip MSRA-TD500.zip -d data \n",
        "os.chdir('/content/data/MSRA-TD500')\n",
        "!ls\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ynrXtntikZaQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('/content/data/MSRA-TD500')\n",
        "!ls\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aF3eKxR3kdCT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "f1 = open(\"train_pair.list\",\"w\")\n",
        "f1.close\n",
        "for root, dirs, files in os.walk(\"train\"): \n",
        "    files.sort()\n",
        "    j=0\n",
        "    for i in range(len(files)//2):\n",
        "        f=open('train_pair.list', 'a') \n",
        "        p=(\"train/\"+files[j]+\" \"+\"train/\"+files[j+1]+\"\\n\")\n",
        "        f.write(p)\n",
        "        #print(\"train/\"+files[j]+\" \"+\"train/\"+files[j+1])\n",
        "        j=j+2\n",
        "        f.close"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jXCUVDRvkeef",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "f1 = open(\"val_pair.list\",\"w\")\n",
        "f1.close\n",
        "for root, dirs, files in os.walk(\"test\"): \n",
        "    files.sort()\n",
        "    j=0\n",
        "    k=0\n",
        "    for i in range(len(files)//2):\n",
        "      if(k<50):\n",
        "        f=open('val_pair.list', 'a') \n",
        "        p=(\"test/\"+files[j]+\"\\n\")\n",
        "        f.write(p)\n",
        "        #print(\"train/\"+files[j]+\" \"+\"train/\"+files[j+1])\n",
        "        j=j+2\n",
        "        k=k+1\n",
        "        f.close"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KsqxdW6UlH4k",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "os.chdir('/content/FCN_Text/TextRegionFCN_Caffe/CAFFE')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9aMJLIvilXtl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!cat deploy.prototxt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YIxsInvElvqF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "yVKOzNRXmE2J",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "k8ZmxoiupkM0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7E6k9n5FsjG5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.pylab as pylab\n",
        "import matplotlib.cm as cm\n",
        "#%matplotlib inline\n",
        "import scipy.misc\n",
        "from PIL import Image\n",
        "import scipy.io\n",
        "import os\n",
        "\n",
        "\n",
        "caffe_root = '/content/caffe/'  # this file is expected to be in {caffe_root}/examples/hed/\n",
        "import sys\n",
        "sys.path.insert(0, caffe_root + 'python')\n",
        "import caffe\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "I48M40B1snnb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data_root = '/content/data/MSRA-TD500/'\n",
        "with open(data_root+'val_pair.list') as f:\n",
        "    test_lst = f.readlines()\n",
        "    \n",
        "test_lst = [data_root+x.strip() for x in test_lst]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zf4idgYYs8yl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "im_lst = []\n",
        "for i in range(0, len(test_lst)):\n",
        "    im = Image.open(test_lst[i])\n",
        "    in_ = np.array(im, dtype=np.float32)\n",
        "    in_ = in_[:,:,::-1]\n",
        "    in_ -= np.array((104.00698793,116.66876762,122.67891434))\n",
        "    im_lst.append(in_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XOnQ7MrgtHFq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def plot_single_scale(scale_lst, size):\n",
        "    pylab.rcParams['figure.figsize'] = size, size/2\n",
        "    \n",
        "    plt.figure()\n",
        "    for i in range(0, len(scale_lst)):\n",
        "        s=plt.subplot(1,5,i+1)\n",
        "        plt.imshow(1-scale_lst[i], cmap = cm.Greys_r)\n",
        "        s.set_xticklabels([])\n",
        "        s.set_yticklabels([])\n",
        "        s.yaxis.set_ticks_position('none')\n",
        "        s.xaxis.set_ticks_position('none')\n",
        "    plt.tight_layout()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Es8RjfAEtD34",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "idx = 1\n",
        "in_ = im_lst[idx]\n",
        "in_ = in_.transpose((2,0,1))\n",
        "#remove the following two lines if testing with cpu\n",
        "caffe.set_mode_gpu()\n",
        "caffe.set_device(0)\n",
        "# load net\n",
        "model_root = '/content/FCN_Text/TextRegionFCN_Caffe/CAFFE/'  \n",
        "net = caffe.Net(model_root+'deploy.prototxt', model_root+'hed_iter_20000.caffemodel', caffe.TEST)\n",
        "# shape for input (data blob is N x C x H x W), set data\n",
        "net.blobs['data'].reshape(1, *in_.shape/2)\n",
        "net.blobs['data'].data[...] = in_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rvzYzjVhucy5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "net.forward() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NhGvHS0ktjZv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "out1 = net.blobs['sigmoid-dsn1'].data[0][0,:,:]\n",
        "out2 = net.blobs['sigmoid-dsn2'].data[0][0,:,:]\n",
        "out3 = net.blobs['sigmoid-dsn3'].data[0][0,:,:]\n",
        "out4 = net.blobs['sigmoid-dsn4'].data[0][0,:,:]\n",
        "out5 = net.blobs['sigmoid-dsn5'].data[0][0,:,:]\n",
        "fuse = net.blobs['sigmoid-fuse'].data[0][0,:,:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0-VY8evWtWlM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "scale_lst = [fuse]\n",
        "plot_single_scale(scale_lst, 22)\n",
        "scale_lst = [out1, out2, out3, out4, out5]\n",
        "plot_single_scale(scale_lst, 10)    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "zfdvbvVImE2Q",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#%%writefile h.py\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.pylab as pylab\n",
        "import matplotlib.cm as cm\n",
        "#%matplotlib inline\n",
        "import scipy.misc\n",
        "from PIL import Image\n",
        "import scipy.io\n",
        "import os\n",
        "\n",
        "\n",
        "caffe_root = '/content/caffe/'  # this file is expected to be in {caffe_root}/examples/hed/\n",
        "import sys\n",
        "sys.path.insert(0, caffe_root + 'python')\n",
        "import caffe\n",
        "\n",
        "\n",
        "\n",
        "data_root = '/content/data/MSRA-TD500/'\n",
        "with open(data_root+'val_pair.list') as f:\n",
        "    test_lst = f.readlines()\n",
        "    \n",
        "test_lst = [data_root+x.strip() for x in test_lst]\n",
        "\n",
        "\n",
        "im_lst = []\n",
        "for i in range(0, len(test_lst)):\n",
        "    im = Image.open(test_lst[i])\n",
        "    in_ = np.array(im, dtype=np.float32)\n",
        "    in_ = in_[:,:,::-1]\n",
        "    in_ -= np.array((104.00698793,116.66876762,122.67891434))\n",
        "    im_lst.append(in_)\n",
        "def plot_single_scale(scale_lst, size):\n",
        "    pylab.rcParams['figure.figsize'] = size, size/2\n",
        "    \n",
        "    \n",
        "    plt.figure()\n",
        "    for i in range(0, len(scale_lst)):\n",
        "        s=plt.subplot(1,5,i+1)\n",
        "        plt.imshow(1-scale_lst[i])\n",
        "        s.set_xticklabels([])\n",
        "        s.set_yticklabels([])\n",
        "        s.yaxis.set_ticks_position('none')\n",
        "        s.xaxis.set_ticks_position('none')\n",
        "    plt.tight_layout()\n",
        "idx = 4\n",
        "\n",
        "in_ = im_lst[idx]\n",
        "in_ = in_.transpose((2,0,1))\n",
        "#remove the following two lines if testing with cpu\n",
        "caffe.set_mode_gpu()\n",
        "caffe.set_device(0)\n",
        "# load net\n",
        "model_root = '/content/FCN_Text/TextRegionFCN_Caffe/CAFFE/'        \n",
        "net = caffe.Net(model_root+'deploy.prototxt', model_root+'hed_iter_20000.caffemodel', caffe.TEST)\n",
        "# shape for input (data blob is N x C x H x W), set data\n",
        "net.blobs['data'].reshape(1, *in_.shape)\n",
        "net.blobs['data'].data[...] = in_\n",
        "# run net and take argmax for prediction\n",
        "net.forward()\n",
        "out1 = net.blobs['sigmoid-dsn1'].data[0][0,:,:]\n",
        "out2 = net.blobs['sigmoid-dsn2'].data[0][0,:,:]\n",
        "out3 = net.blobs['sigmoid-dsn3'].data[0][0,:,:]\n",
        "out4 = net.blobs['sigmoid-dsn4'].data[0][0,:,:]\n",
        "out5 = net.blobs['sigmoid-dsn5'].data[0][0,:,:]\n",
        "fuse = net.blobs['sigmoid-fuse'].data[0][0,:,:]\n",
        "\n",
        "scale_lst = [fuse]\n",
        "plot_single_scale(scale_lst, 22)\n",
        "scale_lst = [out1, out2, out3, out4, out5]\n",
        "plot_single_scale(scale_lst, 10)  \n",
        "print test_lst[idx]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eQp5lMb68i9_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "im1 = Image.open(test_lst[idx])\n",
        "s=plt.subplot(111)\n",
        "plt.imshow(im1)\n",
        "s.set_xticklabels([])\n",
        "s.set_yticklabels([])\n",
        "scale_lst = [fuse]\n",
        "plot_single_scale(scale_lst, 22)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MIjuIELEneha",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!python h.py | tee hed1.log"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "B2EGVWunp_Py",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}